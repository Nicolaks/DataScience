{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost: Predicting heart disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "# Importing the NumPy library for efficient numerical operations, such as working with arrays and performing mathematical computations.\n",
    "\n",
    "import matplotlib.pyplot as plt  \n",
    "# Importing Matplotlib for creating visualizations, which are essential for understanding data trends and model performance.\n",
    "\n",
    "import pandas as pd  \n",
    "# Importing Pandas for data manipulation and analysis, such as loading, transforming, and summarizing datasets using DataFrames.\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score  \n",
    "# Importing various evaluation metrics to measure the performance of classification models, including precision, recall, F1-score, and ROC-AUC.\n",
    "\n",
    "from xgboost import XGBClassifier  \n",
    "# Importing the XGBoost classifier, a powerful and efficient machine learning algorithm optimized for gradient boosting.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "# Importing GridSearchCV to optimize the model's hyperparameters by performing an exhaustive search over a predefined parameter grid.\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "# Importing train_test_split to divide the dataset into training and testing subsets, ensuring proper evaluation of the model's performance.\n",
    "\n",
    "import joblib  \n",
    "# Importing joblib to save and load trained models efficiently, enabling reuse without retraining.\n",
    "\n",
    "import warnings  \n",
    "# Importing warnings to handle and suppress unwanted warning messages for a cleaner notebook output.\n",
    "\n",
    "import os  \n",
    "# Importing os to interact with the file system, enabling navigation and accessing data stored in directories.\n",
    "\n",
    "# Traversing the '/data' directory and its subdirectories to locate data files.\n",
    "for dirname, _, filenames in os.walk('/data'):  \n",
    "    for filename in filenames:  \n",
    "        # Printing the full path of each file to identify available datasets for analysis or modeling.\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "warnings.filterwarnings('ignore')  \n",
    "# Suppressing warnings to improve notebook readability, especially for warnings that do not impact critical operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of modules we will need for this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1888 entries, 0 to 1887\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1888 non-null   int64  \n",
      " 1   sex       1888 non-null   int64  \n",
      " 2   cp        1888 non-null   int64  \n",
      " 3   trestbps  1888 non-null   int64  \n",
      " 4   chol      1888 non-null   int64  \n",
      " 5   fbs       1888 non-null   int64  \n",
      " 6   restecg   1888 non-null   int64  \n",
      " 7   thalachh  1888 non-null   int64  \n",
      " 8   exang     1888 non-null   int64  \n",
      " 9   oldpeak   1888 non-null   float64\n",
      " 10  slope     1888 non-null   int64  \n",
      " 11  ca        1888 non-null   int64  \n",
      " 12  thal      1888 non-null   int64  \n",
      " 13  target    1888 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 206.6 KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/cleaned_merged_heart_dataset.csv\")  \n",
    "# Loading the cleaned and merged heart dataset into a Pandas DataFrame.\n",
    "# The file path \"data/cleaned_merged_heart_dataset.csv\" points to a CSV file containing the processed data.\n",
    "\n",
    "data.info()  \n",
    "# Displaying a concise summary of the dataset, including:\n",
    "# - The number of rows and columns (shape of the DataFrame).\n",
    "# - The data types of each column (e.g., int64, float64, object).\n",
    "# - The number of non-null entries in each column to identify missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description:\n",
    "\n",
    "1. **Structure**:\n",
    "   - The dataset has **1888 rows** (entries) and **14 columns** (features).\n",
    "   - The entries represent individual observations, likely patient records in the context of heart health.\n",
    "\n",
    "2. **Columns**:\n",
    "   - **13 features** (input variables) and **1 target column** (`target`), which may indicate the outcome of interest (e.g., presence or absence of heart disease).\n",
    "   - The features are a mix of integers (`int64`) and one floating-point column (`float64`).\n",
    "\n",
    "3. **Data Quality**:\n",
    "   - All columns have **1888 non-null values**, indicating no missing data.\n",
    "   - This ensures consistency and means no immediate need for imputation or removal of rows/columns due to missing entries.\n",
    "\n",
    "### Insights:\n",
    "This dataset is well-prepared, with no missing values and appropriate data types. It is ready for predicting the `target` variable based on the other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five rows of the dataset:\n",
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalachh  exang  oldpeak  \\\n",
      "0   63    1   3       145   233    1        0       150      0      2.3   \n",
      "1   37    1   2       130   250    0        1       187      0      3.5   \n",
      "2   41    0   1       130   204    0        0       172      0      1.4   \n",
      "3   56    1   1       120   236    0        1       178      0      0.8   \n",
      "4   57    0   0       120   354    0        1       163      1      0.6   \n",
      "\n",
      "   slope  ca  thal  target  \n",
      "0      0   0     1       1  \n",
      "1      0   0     2       1  \n",
      "2      2   0     2       1  \n",
      "3      2   0     2       1  \n",
      "4      2   0     2       1  \n",
      "\n",
      "Summary statistics for numerical columns:\n",
      "               age          sex           cp     trestbps         chol  \\\n",
      "count  1888.000000  1888.000000  1888.000000  1888.000000  1888.000000   \n",
      "mean     54.354343     0.688559     1.279131   131.549258   246.855403   \n",
      "std       9.081505     0.463205     1.280877    17.556985    51.609329   \n",
      "min      29.000000     0.000000     0.000000    94.000000   126.000000   \n",
      "25%      47.750000     0.000000     0.000000   120.000000   211.000000   \n",
      "50%      55.000000     1.000000     1.000000   130.000000   241.000000   \n",
      "75%      61.000000     1.000000     2.000000   140.000000   276.000000   \n",
      "max      77.000000     1.000000     4.000000   200.000000   564.000000   \n",
      "\n",
      "               fbs      restecg     thalachh        exang      oldpeak  \\\n",
      "count  1888.000000  1888.000000  1888.000000  1888.000000  1888.000000   \n",
      "mean      0.148305     0.597458   149.424258     0.331568     1.053761   \n",
      "std       0.355496     0.638820    23.006153     0.470901     1.161344   \n",
      "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000   133.000000     0.000000     0.000000   \n",
      "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
      "75%       0.000000     1.000000   166.000000     1.000000     1.600000   \n",
      "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
      "\n",
      "             slope           ca         thal       target  \n",
      "count  1888.000000  1888.000000  1888.000000  1888.000000  \n",
      "mean      1.421610     0.731462     2.662606     0.517479  \n",
      "std       0.619588     1.015735     1.249924     0.499827  \n",
      "min       0.000000     0.000000     0.000000     0.000000  \n",
      "25%       1.000000     0.000000     2.000000     0.000000  \n",
      "50%       1.000000     0.000000     2.000000     1.000000  \n",
      "75%       2.000000     1.000000     3.000000     1.000000  \n",
      "max       3.000000     4.000000     7.000000     1.000000  \n",
      "\n",
      "Missing values per column:\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalachh    0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display a quick preview of the dataset's structure, statistics, and missing values.\n",
    "\n",
    "# Display the first five rows of the dataset\n",
    "print(\"First five rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Generate summary statistics for numerical columns\n",
    "print(\"\\nSummary statistics for numerical columns:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Check for any missing values in each column\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insights from the Dataset:\n",
    "\n",
    "1. **First Five Rows**:\n",
    "   - The dataset includes features like `age`, `sex`, and `chol` (cholesterol levels), which are numeric and provide clinical or demographic data for each record.\n",
    "   - Features like `cp` (possibly chest pain type), `thal`, and `target` are categorical or ordinal, indicated by their discrete integer values.\n",
    "   - The `target` column appears to represent the outcome (e.g., presence or absence of heart disease), with values of `1` suggesting the presence.\n",
    "\n",
    "2. **Summary Statistics**:\n",
    "   - **Age**: Ranges from 29 to 77, with a mean of ~54. This suggests the dataset covers adults, with most patients in their late 40s to early 60s (based on quartiles).\n",
    "   - **Sex**: Coded as 0 and 1, with a mean of ~0.69, indicating more male patients (likely coded as `1`) than female.\n",
    "   - **Cholesterol (`chol`)**: Values range widely (126 to 564), with a mean of ~247. This variability is typical in medical datasets.\n",
    "   - **Chest Pain Type (`cp`)**: The median (`50%`) is `1`, and the max is `4`, indicating multiple chest pain categories. \n",
    "   - **Resting Blood Pressure (`trestbps`)**: Ranges from 94 to 200, with a mean of ~132, which aligns with typical ranges in clinical settings.\n",
    "\n",
    "3. **Missing Values**:\n",
    "   - No missing values (`0` missing in all columns), indicating the dataset is complete and requires no imputation.\n",
    "\n",
    "### General Observations:\n",
    "- The dataset is well-balanced and clean, making it ready for analysis.\n",
    "- It likely involves a classification task where features are used to predict the `target` variable (e.g., heart disease presence).\n",
    "- Continuous variables (e.g., `chol`, `age`) show variability, which is helpful for machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost Hyperparameter Tuning Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=42, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.8, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n",
       "                         &#x27;max_depth&#x27;: [3, 7, 10, None],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200],\n",
       "                         &#x27;reg_alpha&#x27;: [0, 0.01, 0.1], &#x27;reg_lambda&#x27;: [1, 2],\n",
       "                         &#x27;subsample&#x27;: [0.5, 0.9, 1.0]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=42, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.8, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n",
       "                         &#x27;max_depth&#x27;: [3, 7, 10, None],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200],\n",
       "                         &#x27;reg_alpha&#x27;: [0, 0.01, 0.1], &#x27;reg_lambda&#x27;: [1, 2],\n",
       "                         &#x27;subsample&#x27;: [0.5, 0.9, 1.0]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=42, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.8, 1.0],\n",
       "                         'learning_rate': [0.01, 0.05, 0.1],\n",
       "                         'max_depth': [3, 7, 10, None],\n",
       "                         'n_estimators': [50, 100, 200],\n",
       "                         'reg_alpha': [0, 0.01, 0.1], 'reg_lambda': [1, 2],\n",
       "                         'subsample': [0.5, 0.9, 1.0]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"target\"])  \n",
    "# Removes the target column ('target') from the dataset to use the remaining columns as input features (X).\n",
    "# This step ensures that the target variable is not included as a predictor.\n",
    "\n",
    "y = data[\"target\"]  \n",
    "# Assigns the target column to the variable `y`, representing the dependent variable (output) to be predicted by the model.\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
    "# - Splits the dataset into training (80%) and testing (20%) subsets.\n",
    "# - `test_size=0.2`: Reserves 20% of the data for testing the model's performance.\n",
    "# - `random_state=42`: Ensures reproducibility of the split, meaning the same split will occur every time this code is run.\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Step size for updating weights during gradient descent. Lower values often improve performance but require more trees.\n",
    "    'n_estimators': [50, 100, 200],  # Number of decision trees to build. More trees often improve performance but increase training time.\n",
    "    'max_depth': [3, 7, 10, None],  # Maximum depth of each tree. Deeper trees can capture more complex patterns but may lead to overfitting.\n",
    "    'subsample': [0.5, 0.9, 1.0],  # Proportion of training samples used to fit each tree. Lower values help prevent overfitting.\n",
    "    'colsample_bytree': [0.8, 1.0],  # Proportion of features considered when looking for the best split. Reducing this can improve generalization.\n",
    "    'reg_alpha': [0, 0.01, 0.1],  # Strength of L1 regularization (sparsity-inducing penalty). Helps with feature selection by setting some coefficients to zero.\n",
    "    'reg_lambda': [1, 2]  # Strength of L2 regularization (ridge penalty). Reduces the size of coefficients to prevent overfitting.\n",
    "}\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb = XGBClassifier(objective='binary:logistic', random_state=42, use_label_encoder=False)\n",
    "# - `objective='binary:logistic'`: Specifies that the model is solving a binary classification problem with logistic regression output.\n",
    "# - `random_state=42`: Ensures reproducibility of the model's internal randomness.\n",
    "# - `use_label_encoder=False`: Avoids unnecessary warnings in recent versions of XGBoost.\n",
    "\n",
    "# Perform hyperparameter tuning using Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb, \n",
    "    param_grid=param_grid, \n",
    "    scoring='accuracy',  # Optimizes the model based on accuracy, a common metric for classification tasks.\n",
    "    cv=5,  # Performs 5-fold cross-validation for each combination of parameters to ensure robust evaluation.\n",
    "    verbose=2,  # Prints detailed output about the progress of the grid search.\n",
    "    n_jobs=-1  # Utilizes all available CPU cores to parallelize computations and speed up the search.\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)  \n",
    "# Trains the XGBoost model using the training dataset and evaluates all parameter combinations defined in `param_grid`.\n",
    "# The best combination of hyperparameters is selected based on the highest cross-validation accuracy.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 2, 'subsample': 0.9}\n",
      "Best Score: 0.9708609271523179\n",
      "Precision: 0.9531\n",
      "Recall: 0.9632\n",
      "F1 Score: 0.9581\n",
      "Confusion Matrix:\n",
      "[[179   9]\n",
      " [  7 183]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       188\n",
      "           1       0.95      0.96      0.96       190\n",
      "\n",
      "    accuracy                           0.96       378\n",
      "   macro avg       0.96      0.96      0.96       378\n",
      "weighted avg       0.96      0.96      0.96       378\n",
      "\n",
      "ROC AUC: 0.9922\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_  \n",
    "# - Extracts the model with the optimal hyperparameters found during grid search.\n",
    "# - This model is tuned to maximize cross-validation accuracy.\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)  \n",
    "# - Generates predictions for the test dataset using the tuned model.\n",
    "# - Helps evaluate the model's performance on unseen data.\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)  \n",
    "# - Displays the optimal combination of hyperparameters selected by grid search.\n",
    "# - Useful for understanding which settings lead to the best performance.\n",
    "\n",
    "print(\"Best Score:\", grid_search.best_score_)  \n",
    "# - Prints the highest cross-validation accuracy achieved during grid search.\n",
    "# - Indicates how well the model performed on the training folds.\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)  \n",
    "# - Computes precision, which is the fraction of true positive predictions among all positive predictions.\n",
    "# - High precision means fewer false positives.\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)  \n",
    "# - Computes recall (sensitivity), which is the fraction of true positives correctly identified.\n",
    "# - High recall means fewer false negatives.\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)  \n",
    "# - Computes the F1 score, a metric that balances precision and recall.\n",
    "# - Particularly useful for evaluating models on imbalanced datasets.\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "# - Generates a confusion matrix, summarizing the counts of true positives (TP), false positives (FP), false negatives (FN), and true negatives (TN).\n",
    "# - Helps visualize the model's prediction errors.\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(y_test, y_pred)  \n",
    "# - Produces a detailed report that includes precision, recall, F1-score, and support (number of instances) for each class.\n",
    "# - Useful for multi-class and binary classification performance evaluation.\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# ROC AUC Score (for binary classification)\n",
    "if len(set(y_test)) == 2:  # Check if it's binary classification\n",
    "    auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])  \n",
    "    # - Computes the Area Under the Receiver Operating Characteristic Curve (ROC AUC).\n",
    "    # - The score evaluates the model's ability to discriminate between positive and negative classes across all thresholds.\n",
    "    # - Uses `predict_proba` to obtain probability estimates for the positive class.\n",
    "    print(f\"ROC AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of the Model Evaluation Metrics:\n",
    "\n",
    "1. **Best Parameters**:\n",
    "   - The optimal hyperparameters found by the grid search are:\n",
    "     - `colsample_bytree=0.8`: Uses 80% of the features to train each tree, improving generalization and reducing overfitting.\n",
    "     - `learning_rate=0.05`: A low learning rate enables better convergence with more iterations.\n",
    "     - `max_depth=10`: Allows the model to capture complex patterns without excessive overfitting.\n",
    "     - `n_estimators=200`: Builds 200 trees, providing sufficient complexity and boosting performance.\n",
    "     - `reg_alpha=0`: No L1 regularization applied.\n",
    "     - `reg_lambda=2`: Moderate L2 regularization reduces overfitting by penalizing large coefficients.\n",
    "     - `subsample=0.9`: Uses 90% of the training data for each tree, balancing variance and bias.\n",
    "\n",
    "2. **Best Score**:\n",
    "   - Cross-validation accuracy of **97.09%** indicates the model performs well during training with robust validation, suggesting it generalizes effectively.\n",
    "\n",
    "3. **Evaluation Metrics**:\n",
    "   - **Precision (0.9531)**: The model correctly identifies 95.31% of predicted positives as actual positives, with relatively few false positives.\n",
    "   - **Recall (0.9632)**: The model identifies 96.32% of all actual positives, showing it effectively minimizes false negatives.\n",
    "   - **F1 Score (0.9581)**: The harmonic mean of precision and recall reflects a balanced performance between avoiding false positives and negatives.\n",
    "\n",
    "4. **Confusion Matrix**:\n",
    "   - **True Negatives (TN)**: 179 cases correctly identified as class 0.\n",
    "   - **False Positives (FP)**: 9 cases incorrectly identified as class 1.\n",
    "   - **False Negatives (FN)**: 7 cases incorrectly identified as class 0.\n",
    "   - **True Positives (TP)**: 183 cases correctly identified as class 1.\n",
    "\n",
    "5. **Classification Report**:\n",
    "   - **Class 0**: \n",
    "     - Precision: 96% (proportion of correctly identified negatives among all predicted negatives).\n",
    "     - Recall: 95% (proportion of actual negatives correctly identified).\n",
    "     - F1-Score: 96% (balanced metric).\n",
    "   - **Class 1**: \n",
    "     - Precision: 95%, Recall: 96%, F1-Score: 96%.\n",
    "   - **Overall Accuracy**: **96%**, indicating strong performance across both classes.\n",
    "\n",
    "6. **ROC AUC (0.9922)**:\n",
    "   - Indicates the model’s excellent ability to separate positive and negative classes. A score close to 1 shows high discrimination capability.\n",
    "\n",
    "### **Insights**:\n",
    "- The model is highly accurate and balances precision and recall well, making it effective for tasks requiring a balance between false positives and false negatives.\n",
    "- The ROC AUC value suggests strong discriminatory power, meaning the model is highly reliable across different classification thresholds.\n",
    "- Slight room for improvement may exist by addressing the small number of false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Save the best model to a file\n",
    "joblib.dump(best_model, 'best_xgboost_model.pkl')\n",
    "\n",
    "print(\"Best model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
